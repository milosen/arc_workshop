{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0859a1-27fb-4496-b4fd-f87ab45ea567",
   "metadata": {},
   "source": [
    "# Use your own data\n",
    "\n",
    "In this tutorial, we discuss two ways of using your own data:\n",
    "\n",
    "1. You have one or more lexicons you want to evaluate and generate streams with\n",
    "2. You already have streams and just want to evaluate them\n",
    "\n",
    "If you want to expand ARC, we are happy to invite you to contribute to the [ARC Project](https://github.com/milosen/arc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e43d8-f3f3-4d6b-a756-bb8bb96fc67a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Loading/creating your custom lexicon\n",
    "\n",
    "Let's say you have a lexicon consisting of the (pseudo-)words 'piɾuta', 'baɡoli', 'tokuda, and 'ɡuhaɪbo'.\n",
    "\n",
    "We assume you have prepared your lexicon as a list of lists (see below), and that all syllables are of the same type. The function `to_lexicon()` accepts the syllable types we call 'cv' and 'cV'. 'cv' is a syllable consisting of a single-character consonant and a short vowel, e.g. 'pi'. Because it is common in the literature, 'cv' also allows diphthongs, e.g. 'haɪ'). The 'cV' type is a single-character consonant, together with a long vowel, e.g. 'tuː'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b20f17a-ff7b-46cf-bc4c-7f341ba8adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piɾuta|baɡoli|tokuda|ɡuhaɪbo\n",
      "cumulative_feature_repetitiveness: 7\n"
     ]
    }
   ],
   "source": [
    "from arc import to_lexicon\n",
    "\n",
    "raw_lexicon = [\n",
    "  ['pi', 'ɾu', 'ta'],\n",
    "  ['ba', 'ɡo', 'li'],\n",
    "  ['to', 'ku', 'da'],\n",
    "  ['ɡu', 'haɪ', 'bo']\n",
    "]\n",
    "\n",
    "lexicon = to_lexicon(raw_lexicon, syllable_type=\"cv\")\n",
    "\n",
    "print(lexicon)\n",
    "\n",
    "print(\"cumulative_feature_repetitiveness:\", lexicon.info[\"cumulative_feature_repetitiveness\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19210d47-441f-43fc-ac87-c7eee58252b7",
   "metadata": {},
   "source": [
    "Now turn it into a stream using the `arc` functions introduced earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8de424-9c86-40a3-b709-32ad6278ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piɾutabaɡolitokudaɡuhaɪbo_random|piɾutabaɡolitokudaɡuhaɪbo_word_structured|piɾutabaɡolitokudaɡuhaɪbo_position_controlled\n"
     ]
    }
   ],
   "source": [
    "from arc import make_streams\n",
    "\n",
    "streams = make_streams([lexicon])\n",
    "print(streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d839edd9-9d33-423b-a22c-e99be09edc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to|ɾu|ta|haɪ|ɡu|ɡo|pi|bo|ba|li|ku|da|ɡu|li|bo|ta|to|pi|da|ba|haɪ|ku|ɡo|ɾu|ba|da|ku|ɾu|pi|to|bo|haɪ|li|ɡo|ta|ɡu|ɾu|li|da|haɪ|ɡo|ɡu|bo|pi|ta|ku|ba|to|da|ta|li|pi|ɡu|ku|to|haɪ|bo|ɡo|ba|ɾu|ɡu|to|ba|ta|da|ɡo|li|ɾu|haɪ|pi|ku|bo|li|haɪ|ɾu|ku|ta|pi|ba|bo|ɡu|da|to|ɡo|haɪ|da|li|ba|ɡu|ta|ɡo|bo|ku|pi|ɾu|to|ta|bo|da|ɾu|ɡo|to|ɡu|pi|haɪ|ba|ku|li|to|li|ta|ɾu|da|pi|ɡo|ku|haɪ|bo|ɡu|ba|pi|li|ɡu|haɪ|to|ku|da|bo|ɾu|ta|ba|ɡo|da|haɪ|ta|li|ɾu|bo|to|pi|ba|ku|ɡu|ɡo|bo|ta|pi|ɡu|li|da|to|ɡo|ba|haɪ|ɾu|ku|ba|da|pi|bo|to|ɡu|ta|ku|haɪ|li|ɡo|ɾu|ɡo|haɪ|to|ku|pi|li|ɡu|ba|bo|ɾu|da|ta|ɡu|pi|da|li|ta|to|bo|haɪ|ɡo|ku|ɾu|ba|ɾu|li|haɪ|ba|ɡo|pi|to|ta|bo|da|ku|ɡu|haɪ|ɡu|ɾu|pi|ta|da|ɡo|to|li|ku|bo|ba|ta|ba|li|to|ɾu|bo|pi|haɪ|ku|ɡo|da|ɡu|bo|ɡo|ta|ɾu|ɡu|da|ba|to|haɪ|pi|ku|li|bo|li|pi|ɡo|ɡu|ku|ta|haɪ|da|ɾu|to|ba|ɡu|to|da|bo|ku|ɾu|haɪ|ta|ɡo|li|ba|pi|ɾu|pi|to|da|bo|ɡu|haɪ|ɡo|ta|ba|li|ku|to|pi|ɡo|ɡu|ɾu|bo|ku|ba|haɪ|da|ta|li|ta|da|to|li|bo|ɾu|haɪ|ɡu|ku|pi|ba|ɡo|ku|haɪ|pi|ta|ɡo|bo|to|ɾu|ba|da|li|ɡu|ba|bo|ta|ɡu|pi|ɾu|li|da|haɪ|to|ku|ɡo|haɪ|bo|ba|ɡu|ta|to|ɡo|da|ɾu|ku|li|pi|li|ba|ta|ɾu|ɡu|bo|pi|haɪ|ku|da|ɡo|to|ba|pi|ɡu|ɡo|ɾu|da|ku|to|haɪ|ta|bo|li|ɡo|ba|to|bo|da|pi|ku|ɡu|li|haɪ|ɾu|ta|pi|da|ɡu|to|ta|haɪ|ba|ku|bo|ɡo|li|ɾu|to|ɡu|da|ba|ɾu|ɡo|pi|bo|haɪ|li|ku|ta|ku|pi|ba|ɾu|to|ɡo|da|haɪ|ɡu|bo|ta|li|to|haɪ|ku|ɡu|ɡo|pi|ta|ba|da|ɾu|li|bo|li|to|ku|haɪ|pi|ɾu|ta|ɡo|ba|bo|da|ɡu|da|ku|to|ɡu|ta|haɪ|ɾu|ba|ɡo|li|pi|bo|ɡo|ku|li|haɪ|to|ba|ta|bo|ɾu|da|pi|ɡu|pi|li|ta|ɡu|haɪ|da|ba|to|bo|ku|ɾu|ɡo|bo|ɡu|to|da|ɡo|ta|ɾu|ku|ba|pi|haɪ|li|ɡu|ɾu|pi|ɡo|haɪ|ba|li|da|to|ta|ku|bo|to|li|ɾu|haɪ|ta|pi|da|bo|ba|ku|ɡo|ɡu|ba|ɡu|ku|ta|da|li|ɡo|ɾu|bo|haɪ|pi|to|pi|ku|da|ta|to|ɾu|ɡu|li|haɪ|bo|ba|ɡo|to|ta|ku|li|ba|haɪ|ɡo|bo|pi|ɾu|ɡu|da|ba|ta|ɡu|bo|ɡo|ku|to|haɪ|ɾu|pi|da|li|ba|li|ta|bo|ɾu|ku|ɡu|ɡo|haɪ|da|to|pi|li|bo|ta|haɪ|ɡu|to|ɾu|ba|da|ku|pi|ɡo\n",
      "\n",
      "{'phon_1_son': 0.07017543859649122, 'phon_1_back': 0.07719298245614035, 'phon_1_hi': 0.07719298245614035, 'phon_1_lab': 0.07368421052631578, 'phon_1_cor': 0.0456140350877193, 'phon_1_cont': 0.07017543859649122, 'phon_1_lat': 0.0, 'phon_1_nas': 0.0, 'phon_1_voi': 0.014035087719298246, 'phon_2_back': 0.0, 'phon_2_hi': 0.06666666666666667, 'phon_2_lo': 0.12280701754385964, 'phon_2_lab': 0.09298245614035087, 'phon_2_tense': 0.0, 'phon_2_long': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(streams[0], end=\"\\n\\n\")\n",
    "print(streams[0].info['rhythmicity_indexes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e2702-7363-45b3-a289-2dc051d29570",
   "metadata": {},
   "source": [
    "## Reading in your stream\n",
    "\n",
    "Again, we assume you have prepared your data into a list of syllables like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5e7334-cfc1-4fd4-bc76-08edfefabb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream:  pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo\n",
      "\n",
      "rhythmicity indexes (PRIs) {'phon_1_son': 0.0, 'phon_1_back': 0.3333333333333333, 'phon_1_hi': 0.3333333333333333, 'phon_1_lab': 0.16666666666666666, 'phon_1_cor': 0.0, 'phon_1_cont': 0.0, 'phon_1_lat': 0.0, 'phon_1_nas': 0.0, 'phon_1_voi': 0.0, 'phon_2_back': 0.0, 'phon_2_hi': 0.0, 'phon_2_lo': 0.0, 'phon_2_lab': 0.0, 'phon_2_tense': 0.0, 'phon_2_long': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from arc import to_stream\n",
    "\n",
    "stream = ['pi', 'ɾu', 'ta', 'ba', 'ɡo', 'li', 'to', 'ku', 'da', 'ɡu', 'ki', 'bo']\n",
    "\n",
    "stream = to_stream(stream)\n",
    "\n",
    "print(\"Stream: \", stream, end=\"\\n\\n\")\n",
    "print(\"rhythmicity indexes (PRIs)\", stream.info['rhythmicity_indexes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460fa40-acf5-48a9-b00a-abd0b8f5f970",
   "metadata": {},
   "source": [
    "As you can see, the non-randomized streams have much worse PRIs.\n",
    "\n",
    "This concludes our third and last tutorial. We hope you feel ready to use ARC, and help us extend it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30798f25-a863-4177-a137-6db451c725e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
